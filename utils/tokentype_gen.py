import re

headerPath = "../lang/tokentype.hpp"
sourcePath = "../lang/tokentype.cpp"

with open("tokens.txt", "r") as tokenfile:
	text = "".join(tokenfile.readlines())
	p = re.compile(r"(TOKEN_\w+)")
	tokens = [m.group() for m in p.finditer(text)]

	'''
		Structure of the output file:
		#ifndef clox_tokentype_h
		#define clox_tokentype_h

		#include <string>

		enum TokenType {
			...tokens...
		};

		std::string_view toString(TokenType type){
			switch(type){
				case type: return "TOKEN_";
			}
		}
		
		#undef
	'''

	with open(headerPath, "w") as outputfile:
		print("//DO NOT EDIT: Auto-generated by tokentype_gen.py", file=outputfile)
		print("//If you want to add tokens change tokens.txt", file=outputfile)
		print("#ifndef clox_tokentype_h", file=outputfile)
		print("#define clox_tokentype_h", file=outputfile)
		
		print(file=outputfile)
		print("#include <string>", file=outputfile)
		print(file=outputfile)
		
		print("enum TokenType {", file=outputfile)
		for i in range(len(tokens)):
			print(f"{tokens[i]},", end="\n" if i % 4 == 3 else " "
		 			, file=outputfile)
		print("};", file=outputfile)
		
		print(file=outputfile)
		print("std::string_view tokenTypeToStr(TokenType type);", file=outputfile)
		print(file=outputfile)
		print("#endif", file=outputfile)
		
	with open(sourcePath, "w") as outputfile:
		print("//DO NOT EDIT: Auto-generated by tokentype_gen.py", file=outputfile)
		print("//If you want to add tokens change tokens.txt", file=outputfile)
		print(file=outputfile)
		print('#include "tokentype.hpp"', file=outputfile)
		print("std::string_view tokenTypeToStr(TokenType type) {", file=outputfile)
		print("\tswitch(type) {", file=outputfile)
		for token in tokens:
			print(f'\t\tcase {token}: return "{token}";', file=outputfile)
		print('\t\tdefault: return "UNKNOWN";', file=outputfile)
		print("\t}", file=outputfile)
		print("}", file=outputfile)

		print(file=outputfile)
	